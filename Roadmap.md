# ğŸŸ¢ STAGE A â€” Historical Core Engine (Base sÃ³lida)

ğŸ¯ Objetivo: Motor histÃ³rico confiable y publicable.

A1 â€” Performance
	â€¢	Indexes versioned in schema.sql
	â€¢	Add query execution timer
	â€¢	Add optional EXPLAIN QUERY PLAN debug mode
	â€¢	Detect and reject extremely expensive queries
	â€¢	Add structured logging (question, SQL, execution time, simplification triggered)
	â€¢	Add query benchmark runner
	â€¢	Track LLM generation time separately from SQL execution time

A2 â€” Semantic Quality
	â€¢	Ranking â€œat the timeâ€ rule
	â€¢	Grand Slam rule
	â€¢	Force JOIN to players when returning identities
	â€¢	Add anti-pattern detection (e.g., ranking_date = match_date)

A3 â€” UX Improvements
	â€¢	Format numeric results cleanly
	â€¢	Format player name results nicely
	â€¢	Detect result type automatically
	â€¢	Respond in same language as user

A4 â€” Robustness
	â€¢	API error handling
	â€¢	SQL validation
	â€¢	Add execution timeout
	â€¢	Add max-row safeguard
	â€¢	Add retry with exponential backoff for OpenAI RateLimitError
	â€¢	Add debug mode (--raw, --debug)
	â€¢	Persist query history to logs/query_history.json

ğŸ‘‰ Resultado del Stage A:
Un motor histÃ³rico robusto, presentable en portfolio serio.

# ğŸ”µ STAGE A+ â€” Research & Benchmark Layer

ğŸ¯ Objetivo: Medir capacidad real de razonamiento NL â†’ SQL y documentar performance.

A+1 â€” Stress Test Suite
	â€¢	Create tests/stress_tests.txt
	â€¢	Categorize questions by reasoning difficulty (Level 1â€“5)
	â€¢	Include negative logic, temporal logic, aggregations, comparisons

A+2 â€” Benchmark Runner
	â€¢	Create tests/run_benchmark.py
	â€¢	Execute all stress questions automatically
	â€¢	Measure:
		â€¢	LLM generation time
		â€¢	SQL execution time
		â€¢	Simplification triggered (yes/no)
		â€¢	Timeout occurrences
		â€¢	Empty result anomalies
	â€¢	Persist results to logs/query_benchmark.json

A+3 â€” Metrics & Evaluation
	â€¢	Compute average execution time
	â€¢	Compute simplification rate
	â€¢	Compute failure rate
	â€¢	Identify worst-performing queries
	â€¢	Generate summary report for README

ğŸ‘‰ Resultado del Stage A+:
Motor evaluado experimentalmente con mÃ©tricas objetivas de razonamiento y performance.

# ğŸŸ¡ STAGE B â€” Statistical Expansion

ğŸ¯ Objetivo: Agregar estadÃ­sticas avanzadas.

Necesita ampliar dataset.

B1 â€” Extender schema

Agregar columnas como:
	â€¢	aces
	â€¢	double faults
	â€¢	break points won
	â€¢	service games won
	â€¢	etc.

(Jeff Sackmann tiene estos datos en algunos CSV)

B2 â€” Stats-level queries

Permitir preguntas como:
	â€¢	â€œJugador con mÃ¡s acesâ€
	â€¢	â€œMejor porcentaje de quiebreâ€
	â€¢	â€œMayor win rate en clayâ€
	â€¢	â€œHead-to-head Federer vs Nadal en GSâ€

B3 â€” MÃ©tricas derivadas
	â€¢	Win rate
	â€¢	TÃ­tulos por superficie
	â€¢	Promedios histÃ³ricos
	â€¢	Performance por era

ğŸ‘‰ Resultado del Stage B:
Motor estadÃ­stico comparable a ATP Stats.

# ğŸ”´ STAGE C â€” Full Product Layer

ğŸ¯ Objetivo: Convertirlo en producto real.

C1 â€” API
POST /query

C2 â€” Web UI
	â€¢	Streamlit
	â€¢	O React + backend
	â€¢	Visualizaciones

C3 â€” Conversational Memory
	â€¢	Follow-up questions:
	â€¢	â€œÂ¿Y en clay?â€
	â€¢	â€œÂ¿Y solo Grand Slams?â€

C4 â€” Query Optimizer Agent
	â€¢	LLM genera SQL
	â€¢	Motor analiza costo
	â€¢	Reescribe si es ineficiente

C5 â€” Deploy
	â€¢	Docker
	â€¢	Railway / Render / Fly.io
	â€¢	Hosting pÃºblico

ğŸ‘‰ Resultado del Stage C:
Tennis Guru como producto web consultable pÃºblicamente.